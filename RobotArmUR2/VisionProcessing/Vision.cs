using Emgu.CV;
using Emgu.CV.Structure;
using System.Threading;
using System.Drawing;
using System;
using RobotArmUR2.Util;
using System.Timers;

namespace RobotArmUR2.VisionProcessing {

	/// <summary>Class handles inputing new images and then processing them to detect shapes, and sending the results to be used elsewhere.</summary>
	public class Vision {
		
		/// <summary>The input stream used to grab images.</summary>
		public ImageStream InputStream { get; } = new ImageStream();

		/// <summary>The output collection of images generated by this class.</summary>
		public VisionImages Images { get; private set; }

		/// <summary>The grayscale value used to threshold the input image.</summary>
		public byte GrayscaleThreshold { get; set; } = (byte)(255 / 2);

		#region Events and Handlers
		/// <summary>Fired after an image is inputed then processed. VisionImages is sent as null if the stream was closed.</summary>
		public event NewFrameFinishedHandler OnNewFrameProcessed;
		public delegate void NewFrameFinishedHandler(Vision sender, VisionImages outputs);
		#endregion

		/// <summary>Creates a new input stream and listens to its events.</summary>
		public Vision() {
			InputStream.OnNewImage += InputStream_OnNewImage;
			InputStream.OnStreamEnded += InputStream_OnStreamEnded;
		}

		//Listener fired whenever a new image is grabbed from the input stream.
		private void InputStream_OnNewImage(ImageStream stream, Mat image) {
			VisionImages output = null;

			if (image != null) {
				Image<Bgr, byte> input = image.ToImage<Bgr, byte>();
				Image<Bgr, byte> inputImage = input.Resize(ApplicationSettings.WorkingImageScaledHeight / image.Height, Emgu.CV.CvEnum.Inter.Cubic); //Scale image so Height = 480, but still keeps aspect ratio.

				Image<Gray, byte> grayImage = ImageProcessing.GetGrayImage(inputImage);
				Image<Gray, byte> threshImage = ImageProcessing.GetThresholdImage(grayImage, new Gray(GrayscaleThreshold), new Gray(255));
				Image<Gray, byte> warpedImage = ImageProcessing.GetWarpedImage(threshImage, ApplicationSettings.PaperCalibration);
				UMat edges = ImageProcessing.EdgeDetection(warpedImage);
				Image<Gray, byte> cannyImage = ImageProcessing.GetEdgeImage<Gray, byte>(edges);
				DetectedShapes shapes = ImageProcessing.DetectShapes(edges);
				Image<Bgr, byte> warpedShapes = warpedImage.Convert<Bgr, byte>();
				ImageProcessing.DrawShapes(warpedShapes, shapes, ApplicationSettings.TriangleHighlightColor, ApplicationSettings.SquareHighlightColor, ApplicationSettings.ShapeHighlightThickness);

				output = new VisionImages(input, inputImage, grayImage, threshImage, warpedImage, cannyImage, warpedShapes, shapes);
			}

			Images = output;
			OnNewFrameProcessed?.Invoke(this, output);
		}

		//Listener fired whenever the input stream is closed.
		private void InputStream_OnStreamEnded(ImageStream sender) {
			Images = null;
			OnNewFrameProcessed?.Invoke(this, null);
		}

		/// <summary>Attempts to autodetect the paper. If not found, returns null.</summary>
		/// <param name="images">The collection of images that should be used to detect the paper.</param>
		/// <returns>The attempt at detecting the paper.</returns>
		public RotatedRect? AutoDetectPaper(VisionImages images) {
			if (images == null || images.Input == null) return null;
			Image<Gray, byte> workingImage = ImageProcessing.GetGrayImage(images.Input);
			workingImage = ImageProcessing.GetThresholdImage(workingImage, new Gray(GrayscaleThreshold), new Gray(255));
			UMat edges = ImageProcessing.EdgeDetection(workingImage);

			return ImageProcessing.DetectPaper(edges);
		}

	}

}
